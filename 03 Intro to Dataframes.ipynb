{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to DataFrames\n",
    "\n",
    "The Spark DataFrame API sits on top of the RDD API to provide a SQL-like interface.\n",
    "\n",
    "- [Row](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.Row.html) - A row in DataFrame\n",
    "- [toDf](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.toDF.html) - Returns a new `DataFrame` that with specified column names\n",
    "- [show(n = 20)](https://spark.apache.org/docs/3.2.0/api/python/reference/api/pyspark.sql.DataFrame.show.html) - Prints the first n rows to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark_context = SparkContext.getOrCreate()\n",
    "rdd = spark_context.parallelize(\n",
    "    [\n",
    "        Row(\"Grapes\",   \"500g\", 1.23),\n",
    "        Row(\"Cheddar\",  \"2Mg\",  5600.0),\n",
    "        Row(\"Crackers\", \"16\",   10.20),\n",
    "    ]\n",
    ")\n",
    "shopping_dataframe = rdd.toDF(['name', 'quantity', 'price'])\n",
    "\n",
    "shopping_dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [filter](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.filter.html#pyspark.sql.DataFrame.filter) - Filters rows using the given condition.\n",
    "- [col](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.col.html) - Returns a `Column` based on the given column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "shopping_dataframe.filter(col('price') < 10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Using the existing `shopping_dataframe` print to the console a new DataFrame which contains an additional column called \"price_in_pennies\" calculated by multiplying price by 100.\n",
    "    <details>\n",
    "      <summary>Hint</summary>\n",
    "      Search for \"withColumn\" DataFrame method within the API docs, see Resources below.\n",
    "    </details>\n",
    "1. Using the existing `shopping_dataframe` print to the console a new DataFrame without the name column.\n",
    "    <details>\n",
    "      <summary>Hint</summary>\n",
    "      Search for \"select\" DataFrame method within the API docs, see Resources below.\n",
    "    </details>\n",
    "1. Using the existing `shopping_dataframe` print to the console DataFrame with one column \"name\" where the most expensive item is listed first.\n",
    "    <details>\n",
    "      <summary>Hint</summary>\n",
    "      Search for \"sort\" DataFrame method within the API docs, see Resources below.\n",
    "    </details>\n",
    "1. Save the `shopping_dataframe` to S3 in the JSON format using the path \"s3://shopping-a276085/your_name/\".  Then navigate to the S3 interface and download a copy of the saved shopping.\n",
    "    <details>\n",
    "      <summary>Hint</summary>\n",
    "      Search for \"write\" DataFrame property, and on the returned object a \"json\" method see Resources below.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [DataFrame API docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html)\n",
    "- [Column API docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/column.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc2571f93f1d671bdac87eb973152e0abf55263458b01a56ba6bdd974acd69bc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
