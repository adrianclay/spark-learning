{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Aggregation\n",
    "\n",
    "Aggregation: a cluster of things that have come or been brought together.\n",
    "\n",
    "- [groupBy](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.groupBy.html) - Groups the `DataFrame` using the specified columns, so we can run aggregation on them.  Returns `GroupedData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SparkSession\n",
    "\n",
    "spark_session = SparkSession.builder.getOrCreate()\n",
    "rdd = spark_session.sparkContext.parallelize(\n",
    "    [\n",
    "        Row(\"Adrian\", \"Cake\",   1.23),\n",
    "        Row(\"Adrian\", \"Wine\",   7.00),\n",
    "        Row(\"Dan\",    \"Tea\",    3.20),\n",
    "        Row(\"Dan\",    \"Rum\",    9.20),\n",
    "        Row(\"Fraser\", \"Cheese\", 3.20),\n",
    "        Row(\"Fraser\", \"Cheese\", 4.00),\n",
    "        Row(\"Fraser\", \"Cheese\", 2.00),\n",
    "    ]\n",
    ")\n",
    "shopping_dataframe = rdd.toDF(['name', 'product', 'price'])\n",
    "\n",
    "shopping_dataframe.groupBy('name').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [crosstab](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.crosstab.html#pyspark.sql.DataFrame.crosstab) - Computes a pair-wise frequency table of the given columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopping_dataframe.crosstab('name', 'product').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Using the existing `shopping_dataframe` print to the console a new DataFrame which shows the total price for all products each person has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the existing `shopping_dataframe` print to the console a new DataFrame which shows the average price across all products.\n",
    "    <details>\n",
    "      <summary>Hint</summary>\n",
    "      groupBy can group across any number of columns, including zero.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [GroupedData API](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.GroupedData.html#pyspark.sql.GroupedData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b664d7538e9e6cb83f68b34f1169bfb1b78da0986d7cdad8b8d2121e82a8c8fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
