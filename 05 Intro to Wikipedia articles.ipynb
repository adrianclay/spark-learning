{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Wikipedia Articles\n",
    "\n",
    "Thankfully, the Wikipedia Foundation provides under [their license](https://creativecommons.org/licenses/by-sa/3.0/) free access to their full encylopedia of knowledge via their [dumps website](https://dumps.wikimedia.org/).\n",
    "\n",
    "The work of downloading the data and [processing it into a usable form](https://github.com/attardi/wikiextractor) into an S3 bucket has already been performed for you.\n",
    "\n",
    "- [read.json](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameReader.json.html) - Loads JSON files and returns the results as a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Processing 16.5GB of Wikipedia articles took about 4 minutes during testing.\n",
    "wikipedia_data = spark.read.json(\"s3://wikipedia-dump-extractor-4815879/enwiki-20220701.jsonl\")\n",
    "wikipedia_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [limit](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.limit.html#pyspark.sql.DataFrame.limit) - Limits the result count to the number specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Processing 10 Wikipedia articles took < 1second during testing.\n",
    "wikipedia_data.limit(10).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [printSchema](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.printSchema.html) - Prints out the schema in the tree format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. How many articles have a zero length? What's that as a percentage of the total article count?\n",
    "1. Use the [Soundex](https://en.wikipedia.org/wiki/Soundex) algorithm to find article titles which sound like \"Adrian\".\n",
    "    <details>\n",
    "      <summary>Hint</summary>\n",
    "      To operate on a constant value, e.g. Adrian you can use the pyspark.sql.functions.lit function\n",
    "    </details>\n",
    "1. What is the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) between the number of revisions a wikipedia article has and the length of the article?\n",
    "    <details>\n",
    "      <summary>Hint 1</summary>\n",
    "      The DataFrame object has a method corr which can calculate this.\n",
    "    </details>\n",
    "    <details>\n",
    "      <summary>Hint 2</summary>\n",
    "      The revid column will need to be cast to an integer.\n",
    "    </details>\n",
    "1. What is the most frequently occurring 5 letter word across all articles?\n",
    "    <details>\n",
    "      <summary>Hint 1</summary>\n",
    "      Creating a DataFrame which has a column containing an array of all words within the article could help.\n",
    "    </details>\n",
    "    <details>\n",
    "    <summary>Hint 2</summary>\n",
    "      Manipulating your array of words is hard, but transforming that into a row per word should make filtering and aggregating easier.\n",
    "    </details>\n",
    "1. How does the frequency of letters within Wikipedia compare to [The frequency of the letters of the alphabet in English](https://www3.nd.edu/~busiforc/handouts/cryptography/letterfrequencies.html)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- List of [pyspark.sql.functions](https://spark.apache.org/docs/3.1.3/api/python/reference/pyspark.sql.html#functions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc2571f93f1d671bdac87eb973152e0abf55263458b01a56ba6bdd974acd69bc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
